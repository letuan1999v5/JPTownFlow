// services/geminiService.ts

import { GoogleGenerativeAI } from '@google/generative-ai';
import { AIModelTier, GEMINI_MODELS, canUseModel, InputType, CreditBreakdown } from '../types/credits';
import { deductCredits, checkAndResetCredits } from './creditsService';

// Grounding options
export interface GroundingOptions {
  useGoogleSearch?: boolean;
  useGoogleMaps?: boolean;
}

// Context caching options
// NOTE: Explicit caching requires Cloud Functions (server-side only)
// Currently using Google's Implicit Caching for automatic cost savings
export interface CachingOptions {
  cacheId?: string; // Reserved for future cloud function implementation
  cacheCreatedAt?: Date; // Reserved for future cloud function implementation
  onCacheCreated?: (cacheId: string, createdAt: Date) => void; // Reserved for future cloud function implementation
  onCacheUpdated?: (cacheId: string, updatedAt: Date) => void; // Reserved for future cloud function implementation
}

// Cloud Function URL for explicit caching (optional)
// Set this after deploying Firebase Cloud Functions
const CLOUD_FUNCTION_URL = process.env.EXPO_PUBLIC_GEMINI_CLOUD_FUNCTION_URL || '';
const USE_CLOUD_FUNCTION = Boolean(CLOUD_FUNCTION_URL);

// Debug: Log configuration on module load
console.log('ğŸ”§ [Gemini Service] Cloud Function URL:', CLOUD_FUNCTION_URL ? 'âœ… Configured' : 'âŒ Not configured');
console.log('ğŸ”§ [Gemini Service] USE_CLOUD_FUNCTION:', USE_CLOUD_FUNCTION);
console.log('ğŸ”§ [Gemini Service] Full URL:', CLOUD_FUNCTION_URL);

// Initialize Gemini AI (fallback for direct API calls)
const API_KEY = process.env.EXPO_PUBLIC_GOOGLE_AI_API_KEY || '';
const genAI = new GoogleGenerativeAI(API_KEY);

// Token usage metadata interface with optional detailed breakdown
export interface TokenUsage {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  breakdown?: CreditBreakdown; // Optional detailed credit breakdown (for super admin)
}

// Callback for usage tracking
export type TokenUsageCallback = (usage: TokenUsage) => void;

// Credit check result
export interface CreditCheckResult {
  canProceed: boolean;
  message?: string;
  remainingCredits?: number;
}

// Helper function to handle credit deduction with optional breakdown
async function deductCreditsWithCallback(
  userId: string,
  isSuperAdmin: boolean,
  inputTokens: number,
  outputTokens: number,
  feature: string,
  modelTier: AIModelTier,
  inputType: InputType,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions,
  onTokenUsage?: TokenUsageCallback,
  cachedTokens?: number
): Promise<void> {
  if (!isSuperAdmin) {
    const deductResult = await deductCredits(
      userId,
      inputTokens,
      outputTokens,
      feature,
      modelTier,
      {
        inputType,
        useGroundingSearch: groundingOptions?.useGoogleSearch,
        useGroundingMaps: groundingOptions?.useGoogleMaps,
        useCaching: !!cachingOptions?.cacheId,
        cachedTokens: cachedTokens || 0,
      },
      !!onTokenUsage // Request breakdown if callback is provided
    );

    if (!deductResult.success) {
      throw new Error(deductResult.message || 'Failed to deduct credits');
    }

    // Track credit breakdown if callback provided
    if (onTokenUsage && deductResult.breakdown) {
      const usage: TokenUsage = {
        promptTokens: inputTokens,
        completionTokens: outputTokens,
        totalTokens: inputTokens + outputTokens,
        breakdown: deductResult.breakdown,
      };
      onTokenUsage(usage);
    }
  } else {
    // For super admin, still call callback with token usage (no breakdown needed)
    if (onTokenUsage) {
      const usage: TokenUsage = {
        promptTokens: inputTokens,
        completionTokens: outputTokens,
        totalTokens: inputTokens + outputTokens,
      };
      onTokenUsage(usage);
    }
  }
}

/**
 * Call Cloud Function for Gemini API with explicit caching
 * This provides 90% discount on cached tokens vs implicit caching's 75-90%
 */
async function callGeminiCloudFunction(
  messages: ChatMessage[],
  modelTier: AIModelTier,
  featureType: string,
  cacheId?: string,
  cacheCreatedAt?: Date,
  systemPrompt?: string
): Promise<{
  text: string;
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
    cachedTokens: number;
  };
  cache?: {
    cacheId: string;
    createdAt: string;
  };
  warnings?: string[];
}> {
  const response = await fetch(CLOUD_FUNCTION_URL, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      messages,
      modelTier,
      featureType,
      cacheId,
      cacheCreatedAt: cacheCreatedAt?.toISOString(),
      systemPrompt,
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || 'Cloud function request failed');
  }

  return response.json();
}

// Map language codes to full language names for better AI understanding
const getLanguageName = (languageCode: string): string => {
  const languageMap: Record<string, string> = {
    'ja': 'Japanese',
    'en': 'English',
    'vi': 'Vietnamese',
    'zh': 'Chinese',
    'ko': 'Korean',
    'pt': 'Portuguese',
    'es': 'Spanish',
    'fil': 'Filipino',
    'th': 'Thai',
    'id': 'Indonesian',
  };
  return languageMap[languageCode] || 'English';
};

export interface GarbageAnalysisResult {
  itemName: string; // TÃªn loáº¡i rÃ¡c nháº­n diá»‡n Ä‘Æ°á»£c
  category: string | null; // PhÃ¢n loáº¡i (burnable, plastic, etc.)
  confidence: number; // Äá»™ tin cáº­y (0-100)
  instructions: string; // HÆ°á»›ng dáº«n phÃ¢n loáº¡i
  additionalInfo?: string; // ThÃ´ng tin bá»• sung
}

/**
 * PhÃ¢n tÃ­ch áº£nh rÃ¡c sá»­ dá»¥ng Gemini Vision API
 */
export async function analyzeGarbageImage(
  userId: string,
  userTier: string,
  imageBase64: string,
  wasteCategories: any, // Rules tá»« Firestore
  language: string = 'vi',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<GarbageAnalysisResult> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    // Get the generative model
    const modelName = GEMINI_MODELS[modelTier];
    const model = genAI.getGenerativeModel({ model: modelName });

    // Build categories context for AI
    const categoriesContext = Object.keys(wasteCategories || {})
      .map((cat) => {
        const items = wasteCategories[cat]?.items || [];
        return `${cat}: ${items.slice(0, 5).join(', ')}`;
      })
      .join('\n');

    // Build prompt based on language
    let prompt = '';
    if (language === 'vi') {
      prompt = `
Báº¡n lÃ  chuyÃªn gia phÃ¢n loáº¡i rÃ¡c tháº£i táº¡i Nháº­t Báº£n. HÃ£y phÃ¢n tÃ­ch áº£nh nÃ y vÃ  tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.

CÃC LOáº I RÃC Cá»¦A KHU Vá»°C:
${categoriesContext}

YÃŠU Cáº¦U:
1. Nháº­n diá»‡n Ä‘á»“ váº­t trong áº£nh
2. XÃ¡c Ä‘á»‹nh loáº¡i rÃ¡c phÃ¹ há»£p nháº¥t (dá»±a trÃªn danh sÃ¡ch trÃªn)
3. ÄÆ°a ra hÆ°á»›ng dáº«n cá»¥ thá»ƒ vá» cÃ¡ch vá»©t

Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng JSON:
{
  "itemName": "tÃªn Ä‘á»“ váº­t báº±ng tiáº¿ng Viá»‡t",
  "category": "tÃªn category (burnable, plastic, etc. hoáº·c null náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c)",
  "confidence": sá»‘ tá»« 0-100,
  "instructions": "hÆ°á»›ng dáº«n chi tiáº¿t cÃ¡ch vá»©t",
  "additionalInfo": "thÃ´ng tin bá»• sung (náº¿u cÃ³)"
}
`;
    } else if (language === 'ja') {
      prompt = `
ã‚ãªãŸã¯æ—¥æœ¬ã®ã‚´ãƒŸåˆ†åˆ¥ã®å°‚é–€å®¶ã§ã™ã€‚ã“ã®ç”»åƒã‚’åˆ†æã—ã¦ã€æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚

åœ°åŸŸã®ã‚´ãƒŸåˆ†é¡:
${categoriesContext}

è¦æ±‚äº‹é …:
1. ç”»åƒå†…ã®ç‰©ä½“ã‚’èªè­˜ã™ã‚‹
2. æœ€é©ãªã‚´ãƒŸã®ç¨®é¡ã‚’ç‰¹å®šã™ã‚‹ï¼ˆä¸Šè¨˜ãƒªã‚¹ãƒˆã«åŸºã¥ãï¼‰
3. å…·ä½“çš„ãªæ¨ã¦æ–¹ã®æŒ‡ç¤ºã‚’æä¾›ã™ã‚‹

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "itemName": "æ—¥æœ¬èªã§ã®ç‰©å“å",
  "category": "ã‚«ãƒ†ã‚´ãƒªå (burnable, plasticç­‰ã€ã¾ãŸã¯ä¸æ˜ãªå ´åˆã¯null)",
  "confidence": 0ã‹ã‚‰100ã®æ•°å€¤,
  "instructions": "å…·ä½“çš„ãªæ¨ã¦æ–¹ã®æŒ‡ç¤º",
  "additionalInfo": "è¿½åŠ æƒ…å ±ï¼ˆã‚ã‚‹å ´åˆï¼‰"
}
`;
    } else {
      // English
      prompt = `
You are a garbage sorting expert in Japan. Analyze this image and respond in English.

AREA WASTE CATEGORIES:
${categoriesContext}

REQUIREMENTS:
1. Identify the object in the image
2. Determine the most appropriate waste category (based on the list above)
3. Provide specific disposal instructions

Respond in JSON format:
{
  "itemName": "item name in English",
  "category": "category name (burnable, plastic, etc. or null if uncertain)",
  "confidence": number from 0-100,
  "instructions": "detailed disposal instructions",
  "additionalInfo": "additional information (if any)"
}
`;
    }

    // Convert base64 to proper format for Gemini
    const imagePart = {
      inlineData: {
        data: imageBase64,
        mimeType: 'image/jpeg',
      },
    };

    // Generate content
    const result = await model.generateContent([prompt, imagePart]);
    const response = await result.response;
    const text = response.text();

    // Deduct credits and track usage
    const inputTokens = response.usageMetadata?.promptTokenCount || 0;
    const outputTokens = response.usageMetadata?.candidatesTokenCount || 0;

    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'garbage_analysis',
      modelTier,
      'image',
      groundingOptions,
      cachingOptions,
      onTokenUsage
    );

    // Parse JSON response
    // Remove markdown code blocks if present
    const cleanedText = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    const analysis: GarbageAnalysisResult = JSON.parse(cleanedText);

    return analysis;
  } catch (error) {
    console.error('Gemini API error:', error);
    throw new Error('Failed to analyze image. Please try again.');
  }
}

/**
 * Validate if the analyzed category exists in local rules
 */
export function validateCategory(
  category: string | null,
  wasteCategories: any
): boolean {
  if (!category) return false;
  return Object.keys(wasteCategories || {}).includes(category);
}

/**
 * Get detailed rules for a specific category
 */
export function getCategoryDetails(
  category: string,
  wasteCategories: any
): any {
  return wasteCategories?.[category] || null;
}

// ============================================
// AI ASSISTANT FEATURES
// ============================================

export interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
}

/**
 * General AI Chat Assistant
 */
export async function chatWithAI(
  userId: string,
  userTier: string,
  messages: ChatMessage[],
  language: string = 'en',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<string> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    let cachedTokens = 0;
    let inputTokens = 0;
    let outputTokens = 0;
    let responseText = '';

    // ============================================
    // API CALL - Cloud Function or Direct
    // ============================================
    if (USE_CLOUD_FUNCTION) {
      // Use Cloud Function for explicit caching (90% guaranteed discount)
      const result = await callGeminiCloudFunction(
        messages,
        modelTier,
        'ai_chat',
        cachingOptions?.cacheId,
        cachingOptions?.cacheCreatedAt,
        undefined // No system prompt for general AI chat
      );

      responseText = result.text;
      inputTokens = result.usage.promptTokens;
      outputTokens = result.usage.completionTokens;
      cachedTokens = result.usage.cachedTokens;

      // Handle cache callbacks
      if (result.cache) {
        if (cachingOptions?.cacheId && cachingOptions.cacheId === result.cache.cacheId) {
          // Cache was renewed
          cachingOptions.onCacheUpdated?.(result.cache.cacheId, new Date(result.cache.createdAt));
        } else {
          // New cache created
          cachingOptions?.onCacheCreated?.(result.cache.cacheId, new Date(result.cache.createdAt));
        }
      }

      // Show warnings if any
      if (result.warnings && result.warnings.length > 0) {
        console.warn('Cloud Function warnings:', result.warnings);
        // You can show these to user via Alert if needed
      }
    } else {
      // Fallback: Direct API call (uses Google's Implicit Caching)
      const modelName = GEMINI_MODELS[modelTier];
      const model = genAI.getGenerativeModel({ model: modelName });

      // Build conversation history (exclude last message)
      let history = messages.slice(0, -1).map(msg => ({
        role: msg.role === 'user' ? 'user' : 'model',
        parts: [{ text: msg.content }],
      }));

      // Gemini requires first message to be from user
      while (history.length > 0 && history[0].role === 'model') {
        history = history.slice(1);
      }

      const chat = model.startChat({ history });
      const lastMessage = messages[messages.length - 1].content;

      const result = await chat.sendMessage(lastMessage);
      const response = await result.response;

      responseText = response.text();
      inputTokens = response.usageMetadata?.promptTokenCount || 0;
      outputTokens = response.usageMetadata?.candidatesTokenCount || 0;
      cachedTokens = response.usageMetadata?.cachedContentTokenCount || 0;
    }

    // ============================================
    // CREDIT DEDUCTION
    // ============================================
    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'ai_chat',
      modelTier,
      'text',
      groundingOptions,
      USE_CLOUD_FUNCTION ? cachingOptions : undefined,
      onTokenUsage,
      cachedTokens
    );

    return responseText;
  } catch (error) {
    console.error('Gemini Chat API error:', error);
    throw new Error('Failed to get AI response. Please try again.');
  }
}

/**
 * Japanese Learning AI Assistant with JLPT level support
 */
export async function chatJapaneseLearning(
  userId: string,
  userTier: string,
  messages: ChatMessage[],
  jlptLevel: 'N1' | 'N2' | 'N3' | 'N4' | 'N5',
  userLanguage: string = 'en',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<string> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    // Convert language code to full language name
    const languageName = getLanguageName(userLanguage);

    // System prompt based on JLPT level
    const systemPrompt = `You are a Japanese language teacher helping a student at JLPT ${jlptLevel} level.

CRITICAL FORMATTING RULES - YOU MUST FOLLOW THESE EXACTLY:
1. Use Japanese vocabulary and grammar appropriate for ${jlptLevel} level
2. When you use ANY vocabulary or grammar ABOVE ${jlptLevel} level, you MUST wrap it in this EXACT 3-part format:
   {{kanji|hiragana|translation in ${languageName}}}

3. The format has THREE parts separated by TWO vertical bars |
   - Part 1: Kanji/Japanese word (or hiragana if no kanji exists)
   - Part 2: Hiragana reading
   - Part 3: Translation in ${languageName} (IMPORTANT: Must be in ${languageName}, NOT English)

4. ALWAYS use double curly braces {{ }} - NOT single braces, NOT brackets, NOT parentheses
5. DO NOT use formats like: **word**, **word(reading)**, [translation], (translation), or wordï¼ˆreadingï¼‰
6. DO NOT use furigana format like ä¼šè©±ï¼ˆã‹ã„ã‚ï¼‰ - use {{ä¼šè©±|ã‹ã„ã‚|conversation}} instead

CORRECT EXAMPLES:
- "ä»Šæ—¥ã¯{{æ†§ã‚Œã‚‹|ã‚ã“ãŒã‚Œã‚‹|to admire}}äººã«ã¤ã„ã¦è©±ã—ã¾ã—ã‚‡ã†ã€‚"
- "ã“ã®{{èªå½™|ã”ã„|vocabulary}}ã¯é‡è¦ã§ã™ã€‚"
- "{{ä¸€ç”Ÿæ‡¸å‘½|ã„ã£ã—ã‚‡ã†ã‘ã‚“ã‚ã„|with all one's might}}å‹‰å¼·ã—ã¦ãã ã•ã„ã€‚"
- "æ—¥æœ¬ã§ã¯{{æŒ¨æ‹¶|ã‚ã„ã•ã¤|greeting}}ãŒå¤§åˆ‡ã§ã™ã€‚"
- "{{ä¼šè©±|ã‹ã„ã‚|conversation}}ã®ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†ã€‚"

WRONG EXAMPLES (DO NOT USE THESE):
- "ä»Šæ—¥ã¯**æ†§ã‚Œã‚‹**(ã‚ã“ãŒã‚Œã‚‹)äººã«ã¤ã„ã¦è©±ã—ã¾ã—ã‚‡ã†ã€‚" âŒ
- "ã“ã®èªå½™ï¼ˆã”ã„ï¼‰ã¯é‡è¦ã§ã™ã€‚" âŒ
- "**ä¼šè©±ï¼ˆã‹ã„ã‚ï¼‰** ã®ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†ã€‚" âŒ
- "{{ä¸€ç”Ÿæ‡¸å‘½|with all one's might}}å‹‰å¼·ã—ã¦ãã ã•ã„ã€‚" âŒ (missing hiragana)

FULL EXAMPLE RESPONSE:
"ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­ã€‚
æ–°ã—ã„{{èªå½™|ã”ã„|vocabulary}}ã‚’å‹‰å¼·ã—ã¾ã—ã‚‡ã†ã€‚

ä¾‹ãˆã°ã€{{æ†§ã‚Œã‚‹|ã‚ã“ãŒã‚Œã‚‹|to admire}}ã¨ã„ã†å‹•è©ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯N2ãƒ¬ãƒ™ãƒ«ã®è¨€è‘‰ã§ã™ã€‚
ã€Œç§ã¯æœ‰åãª{{æ­Œæ‰‹|ã‹ã—ã‚…|singer}}ã«æ†§ã‚Œã¦ã„ã¾ã™ã€‚ã€

{{ä¼šè©±|ã‹ã„ã‚|conversation}}ã®ç·´ç¿’ã‚‚å¤§åˆ‡ã§ã™ã€‚
ã€Œå½¼ã¯æ—¥æœ¬èªã§{{ä¸Šæ‰‹|ã˜ã‚‡ã†ãš|skillful}}ã«ä¼šè©±ã§ãã¾ã™ã€‚ã€

é ‘å¼µã£ã¦ãã ã•ã„ï¼"

Remember: Be encouraging and patient. Respond primarily in Japanese, but explain complex concepts in ${languageName} if needed.
CRITICAL: ALL translations in the {{kanji|hiragana|translation}} format MUST be in ${languageName} language.
For example, if the language is Vietnamese, write {{ä¼šè©±|ã‹ã„ã‚|há»™i thoáº¡i}}, NOT {{ä¼šè©±|ã‹ã„ã‚|conversation}}.`;

    let cachedTokens = 0;
    let inputTokens = 0;
    let outputTokens = 0;
    let responseText = '';

    // ============================================
    // API CALL - Cloud Function or Direct
    // ============================================
    if (USE_CLOUD_FUNCTION) {
      // Use Cloud Function for explicit caching (90% guaranteed discount)
      const result = await callGeminiCloudFunction(
        messages,
        modelTier,
        'japanese_learning',
        cachingOptions?.cacheId,
        cachingOptions?.cacheCreatedAt,
        systemPrompt
      );

      responseText = result.text;
      inputTokens = result.usage.promptTokens;
      outputTokens = result.usage.completionTokens;
      cachedTokens = result.usage.cachedTokens;

      // Handle cache callbacks
      if (result.cache) {
        if (cachingOptions?.cacheId && cachingOptions.cacheId === result.cache.cacheId) {
          // Cache was renewed
          cachingOptions.onCacheUpdated?.(result.cache.cacheId, new Date(result.cache.createdAt));
        } else {
          // New cache created
          cachingOptions?.onCacheCreated?.(result.cache.cacheId, new Date(result.cache.createdAt));
        }
      }

      // Show warnings if any
      if (result.warnings && result.warnings.length > 0) {
        console.warn('Cloud Function warnings:', result.warnings);
      }
    } else {
      // Fallback: Direct API call (uses Google's Implicit Caching)
      const modelName = GEMINI_MODELS[modelTier];
      const model = genAI.getGenerativeModel({ model: modelName });

      // Build conversation with system prompt
      const history = [
        {
          role: 'user',
          parts: [{ text: systemPrompt }],
        },
        {
          role: 'model',
          parts: [{ text: `ã¯ã„ã€åˆ†ã‹ã‚Šã¾ã—ãŸã€‚${jlptLevel}ãƒ¬ãƒ™ãƒ«ã§æ•™ãˆã¾ã™ï¼` }],
        },
        ...messages.slice(0, -1).map(msg => ({
          role: msg.role === 'user' ? 'user' : 'model',
          parts: [{ text: msg.content }],
        })),
      ];

      const chat = model.startChat({ history });
      const lastMessage = messages[messages.length - 1].content;

      const result = await chat.sendMessage(lastMessage);
      const response = await result.response;

      responseText = response.text();
      inputTokens = response.usageMetadata?.promptTokenCount || 0;
      outputTokens = response.usageMetadata?.candidatesTokenCount || 0;
      cachedTokens = response.usageMetadata?.cachedContentTokenCount || 0;
    }

    // ============================================
    // CREDIT DEDUCTION
    // ============================================
    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'japanese_learning',
      modelTier,
      'text',
      groundingOptions,
      USE_CLOUD_FUNCTION ? cachingOptions : undefined,
      onTokenUsage,
      cachedTokens
    );

    return responseText;
  } catch (error) {
    console.error('Gemini Japanese Learning API error:', error);
    throw new Error('Failed to get AI response. Please try again.');
  }
}

/**
 * Summarize web page content
 */
export async function summarizeWebContent(
  userId: string,
  userTier: string,
  htmlContent: string,
  language: string = 'en',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<string> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    const modelName = GEMINI_MODELS[modelTier];
    const model = genAI.getGenerativeModel({ model: modelName });

    const languageMap: { [key: string]: string } = {
      en: 'English',
      ja: 'Japanese',
      vi: 'Vietnamese',
      zh: 'Chinese',
      ko: 'Korean',
      pt: 'Portuguese',
      es: 'Spanish',
      fil: 'Filipino',
      th: 'Thai',
      id: 'Indonesian',
    };

    const targetLanguage = languageMap[language] || 'English';

    const prompt = `Please summarize the following web page content in ${targetLanguage}.
Provide a concise summary of the main points (3-5 bullet points).

Web content:
${htmlContent.substring(0, 10000)}...`; // Limit content to avoid token limits

    const result = await model.generateContent(prompt);
    const response = await result.response;

    // Deduct credits and track usage
    const inputTokens = response.usageMetadata?.promptTokenCount || 0;
    const outputTokens = response.usageMetadata?.candidatesTokenCount || 0;

    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'web_summary',
      modelTier,
      'text',
      groundingOptions,
      cachingOptions,
      onTokenUsage
    );

    return response.text();
  } catch (error) {
    console.error('Gemini Web Summary API error:', error);
    throw new Error('Failed to summarize content. Please try again.');
  }
}

/**
 * Answer question about web page content
 */
export async function askAboutWebContent(
  userId: string,
  userTier: string,
  htmlContent: string,
  question: string,
  language: string = 'en',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<string> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    const modelName = GEMINI_MODELS[modelTier];
    const model = genAI.getGenerativeModel({ model: modelName });

    const languageMap: { [key: string]: string } = {
      en: 'English',
      ja: 'Japanese',
      vi: 'Vietnamese',
      zh: 'Chinese',
      ko: 'Korean',
      pt: 'Portuguese',
      es: 'Spanish',
      fil: 'Filipino',
      th: 'Thai',
      id: 'Indonesian',
    };

    const targetLanguage = languageMap[language] || 'English';

    const prompt = `You are a helpful AI assistant. Based on the web page content below, answer the user's question.

CRITICAL INSTRUCTION - LANGUAGE DETECTION:
1. First, detect the language of the user's question
2. ALWAYS respond in THE SAME LANGUAGE as the question, regardless of the targetLanguage parameter
3. If the question is in Vietnamese, respond in Vietnamese
4. If the question is in English, respond in English
5. If the question is in Japanese, respond in Japanese
6. And so on for other languages

Examples:
- Question: "Trang web nÃ y nÃ³i vá» gÃ¬?" â†’ Answer in Vietnamese
- Question: "What is this page about?" â†’ Answer in English
- Question: "ã“ã®ãƒšãƒ¼ã‚¸ã¯ä½•ã«ã¤ã„ã¦ã§ã™ã‹ï¼Ÿ" â†’ Answer in Japanese

User's question: ${question}

Web page content:
${htmlContent.substring(0, 10000)}...

Remember: Respond in the SAME LANGUAGE as the question above.`;

    const result = await model.generateContent(prompt);
    const response = await result.response;

    // Deduct credits and track usage
    const inputTokens = response.usageMetadata?.promptTokenCount || 0;
    const outputTokens = response.usageMetadata?.candidatesTokenCount || 0;

    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'web_qa',
      modelTier,
      'text',
      groundingOptions,
      cachingOptions,
      onTokenUsage
    );

    return response.text();
  } catch (error) {
    console.error('Gemini Web Q&A API error:', error);
    throw new Error('Failed to answer question. Please try again.');
  }
}

/**
 * Translate and explain Japanese text
 */
export async function translateJapanese(
  userId: string,
  userTier: string,
  japaneseText: string,
  targetLanguage: string = 'en',
  modelTier: AIModelTier = 'lite',
  onTokenUsage?: TokenUsageCallback,
  groundingOptions?: GroundingOptions,
  cachingOptions?: CachingOptions
): Promise<string> {
  try {
    // Check if user is super admin (unlimited credits)
    const isSuperAdmin = userTier === 'SUPERADMIN';

    // Check if user can use this model
    if (!isSuperAdmin && !canUseModel(userTier, modelTier)) {
      throw new Error(`Your subscription plan does not support ${modelTier} model. Please upgrade or choose a different model.`);
    }

    // Check and reset credits if needed (unless super admin)
    if (!isSuperAdmin) {
      await checkAndResetCredits(userId, userTier);
    }

    const modelName = GEMINI_MODELS[modelTier];
    const model = genAI.getGenerativeModel({ model: modelName });

    const languageMap: { [key: string]: string } = {
      en: 'English',
      ja: 'Japanese',
      vi: 'Vietnamese',
      zh: 'Chinese',
      ko: 'Korean',
      pt: 'Portuguese',
      es: 'Spanish',
      fil: 'Filipino',
      th: 'Thai',
      id: 'Indonesian',
    };

    const outputLanguage = languageMap[targetLanguage] || 'English';

    const prompt = `You are a professional Japanese translator and language teacher. Analyze the following Japanese text and provide appropriate response in ${outputLanguage}.

INPUT TEXT: "${japaneseText}"

CRITICAL INSTRUCTIONS:
1. ALWAYS respond in ${outputLanguage} language
2. Detect the type of input:
   - Single Kanji (æ¼¢å­—): Explain the kanji meaning, readings (éŸ³èª­ã¿/è¨“èª­ã¿), and common compound words
   - Word/Phrase (å˜èª/ãƒ•ãƒ¬ãƒ¼ã‚º): Translate, explain meaning, and provide 2-3 example sentences
   - Sentence/Paragraph (æ–‡/æ®µè½): Provide natural translation with explanations if needed
   - Nonsense/Invalid: Indicate it's invalid or nonsensical

3. FORMAT YOUR RESPONSE:

   For Single Kanji:
   - Meaning: [translation]
   - Readings: éŸ³èª­ã¿ (on'yomi) / è¨“èª­ã¿ (kun'yomi)
   - Common words: [list 3-5 compound words with this kanji]
   - Example: [1 example sentence using this kanji]

   For Word/Phrase:
   - Translation: [translation]
   - Explanation: [detailed meaning and usage]
   - Examples:
     1. [Japanese sentence] â†’ [Translation]
     2. [Japanese sentence] â†’ [Translation]

   For Sentence/Paragraph:
   - Translation: [natural translation]
   - Notes: [any cultural or grammatical notes if needed]

   For Invalid Input:
   - Simply state: "This text appears to be invalid or nonsensical."

4. Be clear, educational, and helpful
5. IMPORTANT: Write EVERYTHING in ${outputLanguage}, including explanations

Now analyze the text and provide your response:`;

    const result = await model.generateContent(prompt);
    const response = await result.response;

    // Deduct credits and track usage
    const inputTokens = response.usageMetadata?.promptTokenCount || 0;
    const outputTokens = response.usageMetadata?.candidatesTokenCount || 0;

    await deductCreditsWithCallback(
      userId,
      isSuperAdmin,
      inputTokens,
      outputTokens,
      'japanese_translation',
      modelTier,
      'text',
      groundingOptions,
      cachingOptions,
      onTokenUsage
    );

    return response.text();
  } catch (error) {
    console.error('Gemini Translation API error:', error);
    throw new Error('Failed to translate. Please try again.');
  }
}
